{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>K Nearest Neighbors</h1>\n",
    "\n",
    "<h3>Basic info:</h3>\n",
    "<li> Algorithm classifies new objects based on class of majority and k of his closest neighbors.\n",
    "<li> It's example of supervised learning.\n",
    "<li> It's really simply method but it isn't fast so it may not be best choice when dealing with a lot of data.\n",
    "<li> It works in multi dimensional datasets.\n",
    "\n",
    "<h3>How to choose k value</h3>\n",
    "<li> k should be even number if number of classes is odd. Otherwise k should be even.\n",
    "<li> k should be greater than number of classes.\n",
    "\n",
    "<h3>Alternative metrics</h3>\n",
    "<li> Euclidean distance\n",
    "<li> Manhattan distance\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Import stuff</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Configure matplotlib </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [12, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Implementing metrics</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Euclidean metrics:\n",
    "$$\n",
    "  d = \\sqrt{(a_1 - b_1)^2 + (a_2 - b_2)^2 + \\ldots + (a_n - b_n)^2 }\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EuclideanMetrics(p1, p2) -> float:\n",
    "    d = 0\n",
    "    for a, b in zip(p1,p2):\n",
    "        d += (a - b) ** 2\n",
    "    return np.sqrt(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Manhattan metrics </h4>\n",
    "\n",
    "$$\n",
    "d = \\sum^n_{i=0}|p1_i - p2_i|\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ManhattanMetrics(p1, p2) -> float:\n",
    "    d = 0\n",
    "    for a, b in zip (p1, p2):\n",
    "        d += np.abs(a - b)\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Cosinus metrics </h4>\n",
    "\n",
    "$$\n",
    "cos (\\theta) = \\frac{a_x \\cdot b_x + a_y \\cdot b_y}{|a||b|}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CosinusMetrics(p1, p2) -> float:\n",
    "    a =( p1[0] * p2[0] + p1[1] * p2[1] )/(np.linalg.norm(p1) + np.linalg.norm(p2))\n",
    "    return 1 - a "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Normalization </h3>\n",
    "<p>Normalization, in this case, is scaling data to range [0, 1]. It highly improves prediction accuracy of KNN algorithm.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    x_{normalized} = \\frac{x - x_{min}}{x_{max} - x_{min} }\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X):\n",
    "    X_norm= (X - np.min(X, axis=0))/(np.max(X, axis=0) - np.min(X, axis=0))\n",
    "    return X_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Split data </h3>\n",
    "This function let us to split our dataset between train and test parts. This let us check accuracy of our algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, train_ratio=0.75, seed=0):\n",
    "    m = X.shape[0] # count of rows in data\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    idx_perm = np.random.permutation(m)\n",
    "    \n",
    "    X = X[idx_perm]\n",
    "    y = y[idx_perm]\n",
    "\n",
    "    index = int(np.round(train_ratio * m))\n",
    "    \n",
    "    X_train = X[:index, :]\n",
    "    X_test = X[index:, :] \n",
    "    y_train = y[:index]\n",
    "    y_test = y[index:]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>My KNN class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN():\n",
    "    def __init__(self, k=5, metric='Euclidean'):\n",
    "        self.k_ = k\n",
    "        self.metric_ = metric\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X_ = X.copy()\n",
    "        self.y_ = y.copy()\n",
    "\n",
    "    def predict(self, X) -> np.ndarray:\n",
    "        predicted_values = []\n",
    "        for x in X:\n",
    "            # Calculate distance between x and trained points \n",
    "            distances = self.dist(x)\n",
    "            # Sort all objects in X_ by distance to x \n",
    "            # and select k of them that are the closest to x\n",
    "            closest_idx = np.argsort(distances)[:self.k_]\n",
    "            # Return class that has majority of them\n",
    "            predicted_values.append(max(self.y_[closest_idx]))\n",
    "        return np.array(predicted_values)\n",
    "\n",
    "    def dist(self, x) -> list:\n",
    "        distances = []\n",
    "        for x_trained in self.X_:\n",
    "            if self.metric_ == \"Euclidean\":\n",
    "                distances.append(EuclideanMetrics(x, x_trained))\n",
    "            elif self.metric_ == \"Manhattan\":\n",
    "                distances.append(ManhattanMetrics(x, x_trained))\n",
    "            elif self.metric_ == \"Cosinus\":\n",
    "                distances.append(CosinusMetrics(x, x_trained))\n",
    "        return distances\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_predicted = self.predict(X)\n",
    "        return sum(y_predicted == y)/len(y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Examples</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Classification Iris dataset<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly I'm gonna load Iris dataset, choose two features from there and normalize values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data[:, 2:4]  # for now I'll use only two features - just to simplify visualization\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, seed=0)\n",
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train)\n",
    "plt.title(\"Scattered plot of my train data by those two features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNN()\n",
    "knn.fit(X_train, y_train)\n",
    "train_score = knn.score(X_train, y_train)\n",
    "print(f\"Score of predict from training data: {train_score}\")\n",
    "test_score = knn.score(X_test, y_test)\n",
    "print(f\"Score of predict from test data: {test_score}\")\n",
    "\n",
    "y_predicted = knn.predict(X_test)\n",
    "is_prediction_accurate = (y_predicted == y_test)\n",
    "\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, alpha = 0.4)\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], linewidths = 5, c=is_prediction_accurate, cmap=\"RdYlGn\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Transparent points are points I trained my model with. Non-transparend, bigger dots are classified points from test data. Objects classified correctly are green, ottherwise they're red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Example 2 - cos metrics </h3>\n",
    "<p>I took this example from book \"Data Science Algorithms in a Week\", by Dávid Natingga. I choose this one, because it uses cosinus metrics - something I've never used before.</p>\n",
    "<p>\n",
    "First column of data means how many times word \"algorithm\" occured per 1000 words in document. Second column counts how many times word \"Computer\" occured per 1000 words in document. Label column determines subject of particular document - is it about Math or IT.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [\n",
    "    [153, 150],\n",
    "    [105, 97],\n",
    "    [75, 125],\n",
    "    [81,84],\n",
    "    [74, 78],\n",
    "    [90, 63],\n",
    "    [20, 0],\n",
    "    [33, 0],\n",
    "    [105, 10],\n",
    "    [2, 0],\n",
    "    [84, 2],\n",
    "    [12, 0],\n",
    "]\n",
    "\n",
    "X = np.array(X)\n",
    "y = [0]*6 + [1]*6\n",
    "y = np.array(y)\n",
    "\n",
    "x_to_predict = np.array([[41, 42]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0], X[:, 1], c=y, linewidths = 8)\n",
    "plt.scatter(x_to_predict[:,0], x_to_predict[:,1], c = \"red\", linewidths = 8)\n",
    "x_line = np.array(range(160))\n",
    "y_line = 0.3*x_line\n",
    "plt.plot(x_line, y_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>As we can see, our objects aren't in clusters, but all of our IT documents are above the line. Probably we should use other classification algorithm (Naive Bayes maybe) or we could use cosinus metric, that is calculated by angle, not by position. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNN(metric=\"Cosinus\")\n",
    "knn.fit(X, y)\n",
    "y_predicted = knn.predict(x_to_predict)\n",
    "print(y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Bibliography</h3>\n",
    "<li> https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "<li>https://en.wikipedia.org/wiki/Taxicab_geometry\n",
    "<li>https://aszokalski.github.io/AI/KNN.html\n",
    "<li>Data Science Algorithms in a Week, Dávid Natingga, Packt"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fdc7e2822602ca3ffc6dd5398f4164245be80577f6bc72a7c883b57c4ac10aa4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
